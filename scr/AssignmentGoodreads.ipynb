{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba5544b-c036-4249-a391-f119d1e93775",
   "metadata": {},
   "source": [
    "# Assignment Goodreads\n",
    "\n",
    "In this assignment, you are going to work with datasets from Goodreads to automatically collect comics/graphic novels that could potentially be relevant for Graphic Medicine Archive. Goodreads offers a giant collection of Comics and Graphic novels. Each title in this collection comes with meta-data (i.e. additional information). This information contains (amongst other aspects):\n",
    "\n",
    "* a desription\n",
    "* a list of 'popular shelves' (something like sub-genre lists created by users)\n",
    "* an author id (can be mapped to author information in the Goodreads Authors dataset)\n",
    "\n",
    "\n",
    "## Task\n",
    "Your task is to use a keyword search in the popular shelves and book descriptions to extract potentially relevant titles. This notebook contains a couple of steps and hints that can help you along the way. \n",
    "\n",
    "## Goal\n",
    "\n",
    "I made a quick start (using a very sloppy list of keywords and a sloppy search strategy) to create a first version of the result we are aiming for (see `../results/graphic_medicine_goodreads.csv`). I want you to improve this result in several ways:\n",
    "\n",
    "* extend/improve the list of keywords I used (see below)\n",
    "* improve the search strategy (I tokenized the shelf names and descriptions and directly searched in them; it would be much better to use lemmatization as well)\n",
    "* if you have time and energy: take descriptions in different languages into account\n",
    "* any additional information you want to include and can obtain from the data (or other data on the Goodreads website)\n",
    "\n",
    "\n",
    "## Data download\n",
    "\n",
    "Please download the following files from Goodreads (this page https://cseweb.ucsd.edu/~jmcauley/datasets/goodreads.html) and put them in a directory called `data` (see code below to create the directory in the right location). Once you have downloaded the files, please unpack them (by double-clicking on the file). \n",
    "\n",
    "* goodreads_books_comics_graphic.json.gz (under By Genre) - henceforth referred to as **books data**\n",
    "* goodreads_book_authors.json.gz (under Meta-Data of Books) - henceforth referred to as **authors data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f5e6626-f375-4a47-a688-b91b334ef6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages you can/will want to use\n",
    "\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import csv\n",
    "from nltk import tokenize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebb1c396-ec97-44ed-8656-0d83aebf9dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '../data' no need to create the directoy again\n"
     ]
    }
   ],
   "source": [
    "# Creata a data dir (if it doesn't exist already) and place downloads there. \n",
    "try:\n",
    "    os.mkdir('../data')\n",
    "except OSError as error:\n",
    "    print(error, 'no need to create the directoy again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba099f7f-a96c-44ac-b299-3f0db106a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepaths\n",
    "path_dir = '../data/goodreads/'\n",
    "path_comics = f'{path_dir}/goodreads_books_comics_graphic.json'\n",
    "path_authors = f'{path_dir}/goodreads_book_authors.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d211d-e95d-49d1-9ee3-1f0cbba09591",
   "metadata": {},
   "source": [
    "## Step 1: Keywords\n",
    "\n",
    "Define keywords that could help you find relevant titles when searching shelves and the descriptions. Feel free to use the list below as a starting point, but please also feel free to deviate from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb712c4c-6e17-4624-8164-48e4a15492f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my sloppy keywords - to be extended and improved\n",
    "\n",
    "keywords = ['illness', 'mental', 'health', 'sickness', \n",
    "            'ill', 'sick', 'cancer', 'depression', 'ocd', 'trauma', \n",
    "            'suicide', 'anxiety', 'disorder']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f8a5e9-613a-4a25-98a8-93a9a1c9adc8",
   "metadata": {},
   "source": [
    "## Step 2: Understand the data structure from Goodreads\n",
    "\n",
    "Both datasets we work with are structured as json-lists. Json lists are essentially lists of dictionaries. Each dictionary represents one book (in the books data) and one author (in the authors data). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ac18b5e-4017-433d-9319-3dd1a54c67c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the files (code provided)\n",
    "\n",
    "#comics dataset\n",
    "with open(path_comics) as infile:\n",
    "    books = [json.loads(line) for line in infile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ea34fb7-6a2b-468f-b0c1-20fa5de56c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors dataset\n",
    "with open(path_authors) as infile:\n",
    "    authors = [json.loads(line) for line in infile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70a28642-1769-4e5a-a10a-1dc50f25a72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89411\n",
      "829529\n"
     ]
    }
   ],
   "source": [
    "# run this and appreciate how massive these datasets are\n",
    "print(len(books))\n",
    "print(len(authors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b5b8adb-a8a7-4b1f-ba4a-2ebd57497a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isbn \t \n",
      "text_reviews_count \t 1\n",
      "series \t []\n",
      "country_code \t US\n",
      "language_code \t \n",
      "popular_shelves \t [{'count': '228', 'name': 'to-read'}, {'count': '2', 'name': 'graphic-novels'}, {'count': '1', 'name': 'ff-re-2011-till-2015'}, {'count': '1', 'name': 'calibre-list'}, {'count': '1', 'name': 'linseyschussan'}, {'count': '1', 'name': '1-person-narrative'}, {'count': '1', 'name': 'lgbtq-ya'}, {'count': '1', 'name': 'watchlist'}, {'count': '1', 'name': 'next-to-read'}, {'count': '1', 'name': 'sf'}, {'count': '1', 'name': 'sachiko'}, {'count': '1', 'name': 'giveaway-add'}, {'count': '1', 'name': 'friends-in-mind'}, {'count': '1', 'name': 'free-to-read-or-preview-on-goodread'}, {'count': '1', 'name': 'fantasy'}, {'count': '1', 'name': 'dystopian'}, {'count': '1', 'name': 'ck-library'}, {'count': '1', 'name': '23089-ya-fantasy-sf-w-major-lgbt'}]\n",
      "asin \t B00NLXQ534\n",
      "is_ebook \t true\n",
      "average_rating \t 4.12\n",
      "kindle_asin \t \n",
      "similar_books \t ['25653153', '25699172', '23530486', '12984185', '25538377', '23525552', '18215952', '21412122', '25758901']\n",
      "description \t Lillian Ann Cross is forced to live the worst nightmare of her life. She is an everyday middle class American, striving to survive in an everyday changing world. Her life was abruptly\n",
      "turned upsidedown forever as she was kidnapped and forced into a world called \"Hen Fighting.\"\n",
      "A world in which women fight and bets are made upon their bloodshed.Lillian is forced to comply due to the threats made upon her mother's life. Being a loving person her whole life, Lillian finds difficulty grasping her new functions. As she is conditioned to live in her new world, she is subjected to an experimental procedure. A procedure which has taken the lives of a few before her. As she survives, she now has to learn how to live with her new \"implants.\" Implants which strengthen her bones, giving her strength and an upper ability amongst others. Implants which require weekly sustenance, or she will die.\n",
      "format \t \n",
      "link \t https://www.goodreads.com/book/show/25742454-the-switchblade-mamma\n",
      "authors \t [{'author_id': '8551671', 'role': ''}]\n",
      "publisher \t \n",
      "num_pages \t \n",
      "publication_day \t \n",
      "isbn13 \t \n",
      "publication_month \t \n",
      "edition_information \t \n",
      "publication_year \t \n",
      "url \t https://www.goodreads.com/book/show/25742454-the-switchblade-mamma\n",
      "image_url \t https://s.gr-assets.com/assets/nophoto/book/111x148-bcc042a9c91a29c1d680899eff700a03.png\n",
      "book_id \t 25742454\n",
      "ratings_count \t 1\n",
      "work_id \t 42749946\n",
      "title \t The Switchblade Mamma\n",
      "title_without_series \t The Switchblade Mamma\n"
     ]
    }
   ],
   "source": [
    "# Explore the structure of one dictionary in the books data\n",
    "test_book = books[0]\n",
    "for k, v in test_book.items():\n",
    "    print(k, '\\t', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77b59426-ca5f-4a06-9b43-aa4a750f789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_rating \t 3.98\n",
      "author_id \t 604031\n",
      "text_reviews_count \t 7\n",
      "name \t Ronald J. Fields\n",
      "ratings_count \t 49\n"
     ]
    }
   ],
   "source": [
    "# Explore the structure of one dictionary in the authors data\n",
    "test_author = authors[0]\n",
    "for k, v in test_author.items():\n",
    "    print(k, '\\t', v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7702d4d0-10a0-4d1e-b131-c16bfb29683f",
   "metadata": {},
   "source": [
    "## Step 3: Map author ids to author names (warm-up)\n",
    "\n",
    "As you may have noticed in the previous step, the books data contain author information in the form of an author ID (a number). To find the name associated with the ID, we have to look up the ID in the authors data. To make things a bit easier, we will create a dictionary mapping IDs to names, so we can easily obtain the name of an author whenever we have an ID. The dictionary should look like this:\n",
    "\n",
    "```\n",
    "{\n",
    "    123: 'first_name1 last_name1,\n",
    "    456: 'first_name2 last_name2'\n",
    "    \n",
    "}\n",
    "```\n",
    "\n",
    "Complete the code below to fill the dictionary called `author_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cb3e152-7481-4ea0-87b5-01592e6bb68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_dict = dict()\n",
    "for author in authors:\n",
    "    aid = author['author_id']\n",
    "    name = author['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be6870c-3e63-4b3c-87e3-a6d958d7059a",
   "metadata": {},
   "source": [
    "## Step 4: Search for relevant shelves\n",
    "\n",
    "Each book in the books data comes with a list of popular shelves. Use your keywords to search for potentially relevant shelves. We will include all books associated with any of the potentially relevant shelves in the final dataset. You can play with this step a bit to check if your keywords work. It will be helpful to explore what kinds of shelf-names you can find and whether they are likely to contain relevant books. \n",
    "\n",
    "Please also keep track of what keyword you found in a shelf-name. To do this, please store your results in a dictionary called `target_shelves` mapping each shelf to the keyword you identified in its name:\n",
    "\n",
    "`{'shelf_name1': 'keyword2', 'shelf_name2': 'keyword3', 'shelf_name3': 'keyword1'}`\n",
    "\n",
    "Use the code below to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "368b3e3f-b0db-4ea3-bc21-8c3386247a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract all shelf names:\n",
    "all_shelves = set()\n",
    "for b in books: \n",
    "    shelves = b['popular_shelves']\n",
    "    for sh in shelves:\n",
    "        name = sh['name']\n",
    "        all_shelves.add(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "915044d9-9ff1-44b2-a3a4-321c7bd5fd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fantasy-supernatural-paranormal\n",
      "\n",
      "books-to-read-not-in-library\n",
      "social-emotional\n",
      "2011fiction\n",
      "500-essential-gn\n",
      "koleksi-anak-anak\n",
      "read-in-8-17\n",
      "other-2016\n",
      "w-2000-2100\n",
      "m-m-yaoi\n",
      "2017-books-finished\n",
      "one-shots-no-pair\n",
      "book-girlfriends\n",
      "books-that-fucked-me-up\n",
      "boxed\n",
      "couldnt_finish\n",
      "most-wanted-books\n",
      "lit-france\n",
      "sept-2015\n",
      "gladiatorial-or-arena-games\n",
      "nonfiction-adult\n",
      "peanut-butter-sandwich\n",
      "vertaald\n",
      "new-check-this-out\n",
      "13-white\n",
      "fantasy-mystery\n",
      "survival\n",
      "rock-he-kim\n",
      "mlnavidad\n"
     ]
    }
   ],
   "source": [
    "# Print some names to get a feeling for what they look like:\n",
    "n = 0\n",
    "for sh in all_shelves:\n",
    "    print(sh)\n",
    "    n+=1 \n",
    "    if n == 30:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f07d12c-0147-410f-9e54-7189c1942eeb",
   "metadata": {},
   "source": [
    "Now it's time to apply the first keyword search! To search for keywords, tokenize the shelf names. As you can see above, they are joined by a '-' character. Some are also joined by a '\\_' character (not shown in the examples). Check if the name contains any of these charaters and then split the name using a string method. In the next step, iterate over your keywords and check if any of them is in your shelf name. Tip: try it out on one name first, then apply it to all. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "190c6f35-8a54-4009-8ba2-b2ce59871d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found word games gladiatorial-or-arena-games\n"
     ]
    }
   ],
   "source": [
    "# Dummy example: \n",
    "keywords_example = ['illness', 'example', 'games']\n",
    "shelf_name = 'gladiatorial-or-arena-games'\n",
    "shelf_name_words = shelf_name.split('-')\n",
    "for keyword in keywords_example:\n",
    "    if keyword in shelf_name_words:\n",
    "        print('found word', keyword, shelf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1036fca4-1ca5-4d5d-870f-0055a1921ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now apply it to all shelf_names\n",
    "target_shelves = dict()\n",
    "for sh in all_shelves:\n",
    "    pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b82e10-f29d-4b87-94cb-f2ada2a51fe8",
   "metadata": {},
   "source": [
    "## Step 5: Find potentially relevant comics using your shelves\n",
    "\n",
    "Now it's time to go through all books and extract the ones linked to relevant shelves! Store the results in such a way that the books are sorted by the keywords you used to identify the shelves (remember, we sored them in such a way that we mapped the target shelves to their respective keywords. \n",
    "\n",
    "Please store the results in a dictionary called `target_comics` whose keys are the keywords used to identify the shelves and values lists containing all books associated with any of the shelves identified by the keyword. \n",
    "\n",
    "```\n",
    "{\n",
    "'keyword1' : [book_dict1, book_dict2, book_dict3, ...],\n",
    " 'keyword2' : [book_dict4, book_dict5, book_dict6, ...],\n",
    " ...\n",
    " }\n",
    "```\n",
    "\n",
    "Tip: You can use defaultdict to define a dictionary whose values are lists. See toy example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "523017da-e3c7-4ae7-8bf2-332c0ef242f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'h': ['hi', 'hotel'],\n",
       "             't': ['toy', 'thing'],\n",
       "             'g': ['game', 'great']})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy example: Sort words by first letter\n",
    "toy_dict = defaultdict(list)\n",
    "\n",
    "words = ['hi', 'toy', 'game', 'hotel', 'thing', 'great']\n",
    "\n",
    "for word in words:\n",
    "    first_letter = word[0]\n",
    "    toy_dict[first_letter].append(word)\n",
    "toy_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "689900dc-75be-4ecc-974a-04c84940d0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_comics:\n",
    "target_comics = defaultdict(list)\n",
    "\n",
    "for b in books:\n",
    "    shelves =  b['popular_shelves']\n",
    "    # Go through the shelves one by one and check if they are in your target shelves.\n",
    "    # If yes, retrieve the keyword associated with the shelf from your dictionary target_shelves\n",
    "    # Add the keyword and book to the dictionary target_comics in such a way that the book will be appendeded \n",
    "    # to a list associated with the keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5682f215-309d-44f3-8f44-2464f6f92bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many books you collected per keyword:\n",
    "\n",
    "for kw, comics in target_comics.items():\n",
    "    print(kw, len(comics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b06b0-0056-4be6-a182-39bec7abddc2",
   "metadata": {},
   "source": [
    "## Step 6: Create the final csv file\n",
    "\n",
    "Have a look at the example file: '../results/graphic_medicine_goodreads.csv'. Use the books you have collected to create such a file. Add whatever other information you would like to add. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5218ff-8a1f-46ca-8ce3-5fe2f9727a58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
